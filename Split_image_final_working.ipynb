{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877f5b1d",
   "metadata": {},
   "source": [
    "This is going to be a script to split up an image into multiple images so\n",
    "that DDC can act on them in //.\n",
    "\n",
    "The target number of localizations is 4000 (or whatever min_loc is)\n",
    "and there will be some buffer added to each side of the images to avoid boundary\n",
    "effects. -CHB 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d9ebd-0e13-43be-abde-0da1af9d1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Required for 3D plotting\n",
    "\n",
    "def make_into_cell(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Put an array inside an array to consider it a cell in .mat.\"\"\"\n",
    "    container: np.ndarray = np.empty((1, 1), dtype=object)\n",
    "    container[0, 0] = arr\n",
    "    return container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e98686",
   "metadata": {},
   "source": [
    "Importing file, arrange them in proper list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f4ebd-3e2d-40af-bca1-7286689eabfa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables\n",
    "TrueLocalizations = []\n",
    "Photons = []\n",
    "Resolution = []\n",
    "min_loc = 2000\n",
    "\n",
    "# Use tkinter file dialog to mimic uigetfile\n",
    "Tk().withdraw()\n",
    "filename_full = askopenfilename(filetypes=[(\"MAT files\", \"*.mat\")], title=\"Select HMM .mat file\")\n",
    "if not filename_full:\n",
    "    print('Error! No (or wrong) file selected!')\n",
    "    exit()\n",
    "\n",
    "# Separate pathname and filename\n",
    "pathname, filename_only = os.path.split(filename_full)\n",
    "\n",
    "# This will load in all of the localizations from your structure file\n",
    "full_filename = os.path.join(pathname, filename_only)\n",
    "try:\n",
    "    data = sio.loadmat(full_filename, squeeze_me=True, struct_as_record=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading MAT file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Better handling of loaded data - handle both lists and numpy arrays\n",
    "if 'LocalizationsFinal' in data:\n",
    "    #check if there is only one ROI or not\n",
    "    if type(data['LocalizationsFinal'][0][0]) == np.ndarray:\n",
    "        LocalizationsFinal = data['LocalizationsFinal']\n",
    "    else:\n",
    "        LocalizationsFinal = np.array([data['LocalizationsFinal']])\n",
    "else:\n",
    "    LocalizationsFinal = []\n",
    "\n",
    "if 'Frame_Information' in data:\n",
    "    #check if there is only one ROI or not\n",
    "    if type(data['Frame_Information'][0]) == np.ndarray:\n",
    "        Frame_Information = data['Frame_Information']\n",
    "    else:\n",
    "        Frame_Information = np.array([data['Frame_Information']])\n",
    "else:\n",
    "    Frame_Information = []\n",
    "\n",
    "if 'TrueLocalizations' in data:\n",
    "    #check if there is only one ROI or not\n",
    "    if type(data['TrueLocalizations'][0][0]) == np.ndarray:\n",
    "        TrueLocalizations = data['TrueLocalizations']\n",
    "    else:\n",
    "        TrueLocalizations = np.array([data['TrueLocalizations']])\n",
    "else:\n",
    "    TrueLocalizations = []\n",
    "\n",
    "if 'Photons' in data:\n",
    "    #check if there is only one ROI or not\n",
    "    if type(data['Photons'][0]) == np.ndarray:\n",
    "        Photons = data['Photons']\n",
    "    else:\n",
    "        Photons = np.array([data['Photons']])\n",
    "else:\n",
    "    Photons = []\n",
    "\n",
    "if 'Resolution' in data:\n",
    "    Resolution = data['Resolution']\n",
    "else:\n",
    "    Resolution = []\n",
    "\n",
    "Condition = filename_only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efe30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TrueLocalizations)\n",
    "TrueLocalizations\n",
    "TrueLocalizations.shape[1] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901c8c0",
   "metadata": {},
   "source": [
    "Adding zero to third coÃ²umns if it's not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If photons cell does not exist, generate one\n",
    "if len(Photons) == 0 or Photons is None:\n",
    "    Photons = []  # reinitialize as an empty list\n",
    "    for i in range(len(Frame_Information)):\n",
    "        # Add array of one to the list for each frame in photons\n",
    "        Photons.append(np.ones((len(Frame_Information[i]), 1), dtype=int))\n",
    "\n",
    "\n",
    "# Initialize arrays to store split up images\n",
    "LocalizationsFinal_Split = []\n",
    "TrueLocalizations_Split = []\n",
    "Frame_Information_Split = []\n",
    "Photons_Split = []\n",
    "Came_from_image = []\n",
    "Parameters_to_split = []\n",
    "temp_numb_of_loc = []\n",
    "addonarray = []\n",
    "cut1array = []\n",
    "cut2array = []\n",
    "cut3array = []\n",
    "\n",
    "# Just in case you do not actually know the true localizations\n",
    "if len(TrueLocalizations) == 0:\n",
    "    TrueLocalizations = []\n",
    "    for ijk in range(len(Frame_Information)):\n",
    "        TrueLocalizations.append(np.empty((0, 3)))  # Empty array with 3 columns\n",
    "\n",
    "# Process the localizations to ensure 3D format\n",
    "processed_localizations = []\n",
    "processed_true_localizations = []\n",
    "\n",
    "# Print debug info about loaded data\n",
    "print(f\"Number of frames: {len(LocalizationsFinal)}\")\n",
    "print(LocalizationsFinal)\n",
    "\n",
    "\n",
    "# Adding zero to the z coordinate if it is not present\n",
    "for sdfv in range(len(LocalizationsFinal)):\n",
    "    # Debug info\n",
    "    print(f\"Processing frame {sdfv+1}: \", end=\"\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    try:\n",
    "        if not isinstance(LocalizationsFinal[sdfv], np.ndarray):\n",
    "            LF = np.array(LocalizationsFinal[sdfv], dtype=float)\n",
    "        else:\n",
    "            LF = LocalizationsFinal[sdfv].copy()\n",
    "        \n",
    "        \n",
    "        print(f\"shape: {LF.shape if hasattr(LF, 'shape') else 'scalar'}, size: {LF.size if hasattr(LF, 'size') else 1}\")\n",
    "        \n",
    "        # Handle different shapes\n",
    "        if LF.shape[1] == 2:\n",
    "            processed_localizations.append(\n",
    "                np.column_stack((\n",
    "                    LF,\n",
    "                    np.zeros((LF.shape[0], 1))\n",
    "                    ))\n",
    "                )\n",
    "        else:\n",
    "            # Already has 3+ columns, use first 3\n",
    "            processed_localizations.append(LF[:, :3])\n",
    "            print(f\"Handled 2D array with final shape {processed_localizations[-1].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing LocalizationsFinal for frame {sdfv}: {e}\")\n",
    "        processed_localizations.append(np.empty((0, 3)))\n",
    "    \n",
    "    # Do the same for TrueLocalizations\n",
    "    try:\n",
    "        if not isinstance(TrueLocalizations[sdfv], np.ndarray):\n",
    "            TL = np.array(TrueLocalizations[sdfv], dtype=float)\n",
    "        else:\n",
    "            TL = TrueLocalizations[sdfv].copy()\n",
    "        \n",
    "        \n",
    "        # Handle different shapes\n",
    "        if TL.shape[1] == 2:\n",
    "            processed_true_localizations.append(\n",
    "                np.column_stack((\n",
    "                    TL,\n",
    "                    np.zeros((TL.shape[0], 1))\n",
    "                    ))\n",
    "                )\n",
    "        else:\n",
    "            # Already has 3+ columns, use first 3\n",
    "            processed_true_localizations.append(TL[:, :3])\n",
    "            print(f\"Handled 2D array with final shape {processed_true_localizations[-1].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing TrueLocalizations for frame {sdfv}: {e}\")\n",
    "        processed_true_localizations.append(np.empty((0, 3)))\n",
    "\n",
    "# Replace the original lists with processed ones\n",
    "LocalizationsFinal = processed_localizations\n",
    "if len(processed_true_localizations) > 0:\n",
    "    TrueLocalizations = processed_true_localizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_true_localizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e263b1",
   "metadata": {},
   "source": [
    "Check if input of Matlab and Python are same before main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12431342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Transpose to (4000, 24, 3)\n",
    "arr_transposed = np.array(LocalizationsFinal).transpose(1, 0, 2)\n",
    "# Step 2: Reshape to (4000, 24*3)\n",
    "Localization_final_reshaped = arr_transposed.reshape(len(LocalizationsFinal[0]), len(LocalizationsFinal) * len(LocalizationsFinal[0][0]))\n",
    "np.savetxt('output-python.txt', Localization_final_reshaped , delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecf827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check thorugh pandas\n",
    "import pandas as pd\n",
    "df_python=pd.DataFrame(Localization_final_reshaped)\n",
    "df_matlab=pd.read_csv('output.txt', sep='\\t', header=None) \n",
    "\n",
    "#Calculate the difference between the two dataframes and check if it is zero\n",
    "df_diff = df_python - df_matlab\n",
    "np.any(df_diff>0.1)\n",
    "np.any(df_diff<-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26300573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/6\n",
      "[   0   25   26 ... 3975 3976 3987]\n",
      "[   0    1    2 ... 3984 3986 3987]\n",
      "[   1    2    3 ... 3983 3984 3985]\n",
      "[   0    1    2 ... 3985 3986 3987]\n",
      "[   1    2    3 ... 3997 3998 3999]\n",
      "[   1    2    3 ... 3987 3994 3997]\n",
      "[   1    2    3 ... 3997 3998 3999]\n",
      "[   1    2    3 ... 3997 3998 3999]\n",
      "[   1    2    3 ... 3997 3998 3999]\n",
      "[   1    2    3 ... 3997 3998 3999]\n",
      "Processing frame 2/6\n",
      "[   0    1    2 ... 3996 3997 3998]\n",
      "[   0    1    2 ... 3996 3997 3998]\n",
      "[   0    1    2 ... 3996 3997 3998]\n",
      "[   0    1    2 ... 3996 3997 3998]\n",
      "[   5    6    7 ... 3996 3997 3999]\n",
      "[  14   15   16 ... 3996 3997 3998]\n",
      "[   5    6   31 ... 3996 3998 3999]\n",
      "[  18   20   33 ... 3996 3998 3999]\n",
      "[  18   46   47 ... 3996 3998 3999]\n",
      "[  18   20   33 ... 3996 3998 3999]\n"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "counter = 0\n",
    "for ksu in range(2):\n",
    "    print(f\"Processing frame {ksu+1}/{len(Frame_Information)}\")\n",
    "    \n",
    "    # Get the localization data\n",
    "    LF = LocalizationsFinal[ksu]\n",
    "    \n",
    "    # Extract columns - now we know LF has 3 columns\n",
    "    X1, X2, X3 = LF[:,0], LF[:,1], LF[:,2]\n",
    "    \n",
    "    # Handle TrueLocalizations for this frame\n",
    "    has_true_loc = (ksu < len(TrueLocalizations) and \n",
    "                    TrueLocalizations[ksu].size > 0)\n",
    "    \n",
    "    if has_true_loc:\n",
    "        TL = TrueLocalizations[ksu]\n",
    "        X1t, X2t, X3t = TL[:,0], TL[:,1], TL[:,2]\n",
    "    \n",
    "    X4 = Frame_Information[ksu].copy()\n",
    "    addon = 250  # Buffer region\n",
    "    \n",
    "    # Phase space search\n",
    "    scorefinal = np.inf\n",
    "    onwers = 1\n",
    "\n",
    "    ppf , ppf2, ppf3 = 0.2, 0.5, 1\n",
    "    \n",
    "    # Set parameters based on results\n",
    "    pp, pp2, pp3 = ppf, ppf2, ppf3\n",
    "    \n",
    "    if len(X1) < min_loc:\n",
    "        ppf = pp = ppf2 = pp2 = ppf3 = pp3 = 1\n",
    "    \n",
    "    flag = 0\n",
    "\n",
    "\n",
    "    #Now that we know the optimum way to split up our specific image, we\n",
    "    #now split it up. \n",
    "    pp = ppf\n",
    "    pp2 = ppf2\n",
    "    pp3 = ppf3\n",
    "\n",
    "    if len(X1) < min_loc:\n",
    "        ppf = 1\n",
    "        ppf2 = 1\n",
    "        ppf3 = 1\n",
    "        pp = ppf\n",
    "        pp2 = ppf2\n",
    "        pp3 = ppf3\n",
    "\n",
    "    flag = 0\n",
    "\n",
    "    for i in range(1, math.ceil(1/pp) + 1):\n",
    "        if flag == 1:\n",
    "            break\n",
    "        \n",
    "        if i*pp < 1:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, i*pp])\n",
    "        else:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, 1])\n",
    "        \n",
    "        for ii in range(1, math.ceil(1/pp2) + 1):\n",
    "            if ii*pp2 < 1:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, ii*pp2])\n",
    "            else:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, 1])\n",
    "            \n",
    "            for iii in range(1, math.ceil(1/pp3) + 1):\n",
    "                if iii*pp3 < 1:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, iii*pp3])\n",
    "                else:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, 1])\n",
    "\n",
    "                addon = addont\n",
    "                \n",
    "                IND = np.array([], dtype=int)\n",
    "                if len(X1) > min_loc:\n",
    "                    # Increase addon until we have enough indices\n",
    "                    while len(IND) < min_loc:\n",
    "                        addon = addon + 10\n",
    "                        IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                        (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                        (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                else:\n",
    "                    IND = np.arange(len(X1))\n",
    "                print(IND[0:10])\n",
    "                while len(IND) > min_loc:\n",
    "                    addon = addon - 10\n",
    "                    IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                    (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                    (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                    if addon < 150:\n",
    "                        break\n",
    "                    \n",
    "                if (len(TrueLocalizations) != 0) and (isinstance(TrueLocalizations[ksu], np.ndarray)) and (TrueLocalizations[ksu].size != 0):\n",
    "                    INDt = np.where((X1t > (cut1[0] - addon)) & (X1t < (cut1[1] + addon)) & \\\n",
    "                                    (X2t > (cut2[0] - addon)) & (X2t < (cut2[1] + addon)) & \\\n",
    "                                    (X3t >= (cut3[0] - addon)) & (X3t <= (cut3[1] + addon)))[0]\n",
    "\n",
    "                # Visualize\n",
    "                # try:\n",
    "                #     plt.figure(1, figsize=(8, 6))\n",
    "                #     plt.clf()  # Clear figure first\n",
    "\n",
    "                #     if len(IND) > 0 and len(X4) >= max(IND) + 1:\n",
    "                #         c_values = X4[IND]\n",
    "                #     else:\n",
    "                #         c_values = np.ones(len(IND))\n",
    "                #         print(\"Using default colors for visualization\")\n",
    "\n",
    "                #     if np.all(X3[IND] == 0):  # 2D plot\n",
    "                #         sc = plt.scatter(X1[IND], X2[IND], s=10, c=c_values, cmap='jet')\n",
    "                #         plt.axis('equal')\n",
    "                #         plt.colorbar(sc)\n",
    "                #     else:  # 3D plot\n",
    "                #         ax = plt.axes(projection='3d')\n",
    "                #         sc = ax.scatter(X1[IND], X2[IND], X3[IND], s=10, c=c_values, cmap='jet')\n",
    "                #         plt.colorbar(sc)\n",
    "                #         plt.tight_layout()\n",
    "\n",
    "                #     plt.title(f\"Split {counter+1}: {len(IND)} points\")\n",
    "                #     plt.draw()\n",
    "                #     plt.pause(0.5)\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Warning: Failed to create plot: {e}\")\n",
    "                print(IND)\n",
    "\n",
    "                # Append split data\n",
    "                LF_split = np.column_stack((X1[IND], X2[IND], X3[IND]))\n",
    "                LocalizationsFinal_Split.append(LF_split)\n",
    "                Photons_Split.append(Photons[ksu][IND])\n",
    "                \n",
    "                if (len(TrueLocalizations) != 0) and (isinstance(TrueLocalizations[ksu], np.ndarray)) and (TrueLocalizations[ksu].size != 0):\n",
    "                    TL_split = np.column_stack((X1t[INDt], X2t[INDt], X3t[INDt]))\n",
    "                    TrueLocalizations_Split.append(TL_split)\n",
    "                else:\n",
    "                    TrueLocalizations_Split.append(np.array([]))\n",
    "                \n",
    "                cut1array.append(cut1)\n",
    "                cut2array.append(cut2)\n",
    "                cut3array.append(cut3)\n",
    "                # For Frame_Information, select indices\n",
    "                X4_ind = X4[IND]\n",
    "                Frame_Information_Split.append(X4_ind)\n",
    "                Came_from_image.append(ksu)\n",
    "                Parameters_to_split.append([ppf, ppf2, ppf3])\n",
    "                addonarray.append(addon)\n",
    "                temp_numb_of_loc.append(len(IND))\n",
    "                \n",
    "                #This will account for images that allready have less than\n",
    "                #the need number of localizations.\n",
    "                if len(X1) < min_loc:\n",
    "                    flag = 1\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fd172ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_result = sio.loadmat('Split_simple2.mat', squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7693aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 461 9457 9458 ... 1729 1730 3177]\n",
      "[5429 5438 5456 ... 4229 6556 6558]\n"
     ]
    }
   ],
   "source": [
    "print(matlab_result['Frame_Information'][0])\n",
    "print(Frame_Information_Split[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11fa6a",
   "metadata": {},
   "source": [
    "\n",
    "Choose one mainloop:\n",
    "1. Adding data through append\n",
    "2. Adding data in Matlab style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159c9f4",
   "metadata": {},
   "source": [
    "First case : Adding data through append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0acfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing loop\n",
    "counter = 0\n",
    "for ksu in range(len(Frame_Information)):\n",
    "    print(f\"Processing frame {ksu+1}/{len(Frame_Information)}\")\n",
    "    \n",
    "    # Get the localization data\n",
    "    LF = LocalizationsFinal[ksu]\n",
    "    \n",
    "    # Extract columns - now we know LF has 3 columns\n",
    "    X1, X2, X3 = LF[:,0], LF[:,1], LF[:,2]\n",
    "    \n",
    "    # Handle TrueLocalizations for this frame\n",
    "    has_true_loc = (ksu < len(TrueLocalizations) and \n",
    "                    TrueLocalizations[ksu].size > 0)\n",
    "    \n",
    "    if has_true_loc:\n",
    "        TL = TrueLocalizations[ksu]\n",
    "        X1t, X2t, X3t = TL[:,0], TL[:,1], TL[:,2]\n",
    "    \n",
    "    X4 = Frame_Information[ksu].copy()\n",
    "    addon = 250  # Buffer region\n",
    "    \n",
    "    # Phase space search\n",
    "    scorefinal = np.inf\n",
    "    onwers = 1\n",
    "\n",
    "    while onwers < 300:\n",
    "        print(f'Phase space search progress: {onwers/300:.2f}')\n",
    "        temp_numb_of_loc = []\n",
    "        onwers += 1\n",
    "        random.seed(10)\n",
    "        pp = random.random()*0.95 + 0.05\n",
    "        pp2 = random.random()*0.95 + 0.05\n",
    "        pp3 = random.random()*0.95 + 0.05 if np.max(X3) != 0 else 1\n",
    "\n",
    "        # Loop over quantile partitions\n",
    "        for i in range(1, math.ceil(1/pp)+1):\n",
    "            if i*pp < 1:\n",
    "                cut1 = np.quantile(X1, [(i-1)*pp, i*pp])\n",
    "            else:\n",
    "                cut1 = np.quantile(X1, [(i-1)*pp, 1])\n",
    "            \n",
    "            for ii in range(1, math.ceil(1/pp2)+1):      \n",
    "                if ii*pp2 < 1:\n",
    "                    cut2 = np.quantile(X2, [(ii-1)*pp2, ii*pp2])\n",
    "                else:\n",
    "                    cut2 = np.quantile(X2, [(ii-1)*pp2, 1])\n",
    "                \n",
    "                for iii in range(1, math.ceil(1/pp3)+1):\n",
    "                    if iii*pp3 < 1:\n",
    "                        cut3 = np.quantile(X3, [(iii-1)*pp3, iii*pp3])\n",
    "                    else:\n",
    "                        cut3 = np.quantile(X3, [(iii-1)*pp3, 1])\n",
    "                    \n",
    "                    # Find indices with conditions and buffer addon\n",
    "                    IND = np.where((X1 >= (cut1[0] - addon)) & (X1 <= (cut1[1] + addon)) & \n",
    "                                   (X2 >= (cut2[0] - addon)) & (X2 <= (cut2[1] + addon)) & \n",
    "                                   (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                    temp_numb_of_loc.append(len(IND))\n",
    "        \n",
    "        # Scoring function\n",
    "        if not temp_numb_of_loc:  # Handle empty list\n",
    "            continue\n",
    "            \n",
    "        # Calculate score\n",
    "        Resid = np.array(temp_numb_of_loc) - min_loc\n",
    "        score = np.sum(Resid**2) / len(temp_numb_of_loc)\n",
    "        \n",
    "        if score < scorefinal:\n",
    "            scorefinal = score\n",
    "            ppf, ppf2, ppf3 = pp, pp2, pp3\n",
    "            onwers = -onwers  # Reset counter\n",
    "            temp_numb_of_locf = temp_numb_of_loc.copy()\n",
    "    \n",
    "    addont = addon\n",
    "    \n",
    "    # Set parameters based on results\n",
    "    pp, pp2, pp3 = ppf, ppf2, ppf3\n",
    "    \n",
    "    if len(X1) < min_loc:\n",
    "        ppf = pp = ppf2 = pp2 = ppf3 = pp3 = 1\n",
    "    \n",
    "    flag = 0\n",
    "\n",
    "\n",
    "    #Now that we know the optimum way to split up our specific image, we\n",
    "    #now split it up. \n",
    "    pp = ppf\n",
    "    pp2 = ppf2\n",
    "    pp3 = ppf3\n",
    "\n",
    "    if len(X1) < min_loc:\n",
    "        ppf = 1\n",
    "        ppf2 = 1\n",
    "        ppf3 = 1\n",
    "        pp = ppf\n",
    "        pp2 = ppf2\n",
    "        pp3 = ppf3\n",
    "\n",
    "    flag = 0\n",
    "\n",
    "    for i in range(1, math.ceil(1/pp) + 1):\n",
    "        if flag == 1:\n",
    "            break\n",
    "        \n",
    "        if i*pp < 1:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, i*pp])\n",
    "        else:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, 1])\n",
    "        \n",
    "        for ii in range(1, math.ceil(1/pp2) + 1):\n",
    "            if ii*pp2 < 1:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, ii*pp2])\n",
    "            else:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, 1])\n",
    "            \n",
    "            for iii in range(1, math.ceil(1/pp3) + 1):\n",
    "                if iii*pp3 < 1:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, iii*pp3])\n",
    "                else:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, 1])\n",
    "\n",
    "                addon = addont\n",
    "                \n",
    "                IND = np.array([], dtype=int)\n",
    "                if len(X1) > min_loc:\n",
    "                    # Increase addon until we have enough indices\n",
    "                    while len(IND) < min_loc:\n",
    "                        addon = addon + 10\n",
    "                        IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                        (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                        (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                else:\n",
    "                    IND = np.arange(len(X1))\n",
    "                \n",
    "                while len(IND) > min_loc:\n",
    "                    addon = addon - 10\n",
    "                    IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                    (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                    (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                    if addon < 150:\n",
    "                        break\n",
    "                    \n",
    "                if (len(TrueLocalizations) != 0) and (isinstance(TrueLocalizations[ksu], np.ndarray)) and (TrueLocalizations[ksu].size != 0):\n",
    "                    INDt = np.where((X1t > (cut1[0] - addon)) & (X1t < (cut1[1] + addon)) & \\\n",
    "                                    (X2t > (cut2[0] - addon)) & (X2t < (cut2[1] + addon)) & \\\n",
    "                                    (X3t >= (cut3[0] - addon)) & (X3t <= (cut3[1] + addon)))[0]\n",
    "\n",
    "                # Visualize\n",
    "                try:\n",
    "                    plt.figure(1, figsize=(8, 6))\n",
    "                    plt.clf()  # Clear figure first\n",
    "\n",
    "                    if len(IND) > 0 and len(X4) >= max(IND) + 1:\n",
    "                        c_values = X4[IND]\n",
    "                    else:\n",
    "                        c_values = np.ones(len(IND))\n",
    "                        print(\"Using default colors for visualization\")\n",
    "\n",
    "                    if np.all(X3[IND] == 0):  # 2D plot\n",
    "                        sc = plt.scatter(X1[IND], X2[IND], s=10, c=c_values, cmap='jet')\n",
    "                        plt.axis('equal')\n",
    "                        plt.colorbar(sc)\n",
    "                    else:  # 3D plot\n",
    "                        ax = plt.axes(projection='3d')\n",
    "                        sc = ax.scatter(X1[IND], X2[IND], X3[IND], s=10, c=c_values, cmap='jet')\n",
    "                        plt.colorbar(sc)\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                    plt.title(f\"Split {counter+1}: {len(IND)} points\")\n",
    "                    plt.draw()\n",
    "                    plt.pause(0.5)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to create plot: {e}\")\n",
    "                \n",
    "                # Append split data\n",
    "                LF_split = np.column_stack((X1[IND], X2[IND], X3[IND]))\n",
    "                LocalizationsFinal_Split.append(LF_split)\n",
    "                Photons_Split.append(Photons[ksu][IND])\n",
    "                \n",
    "                if (len(TrueLocalizations) != 0) and (isinstance(TrueLocalizations[ksu], np.ndarray)) and (TrueLocalizations[ksu].size != 0):\n",
    "                    TL_split = np.column_stack((X1t[INDt], X2t[INDt], X3t[INDt]))\n",
    "                    TrueLocalizations_Split.append(TL_split)\n",
    "                else:\n",
    "                    TrueLocalizations_Split.append(np.array([]))\n",
    "                \n",
    "                cut1array.append(cut1)\n",
    "                cut2array.append(cut2)\n",
    "                cut3array.append(cut3)\n",
    "                # For Frame_Information, select indices\n",
    "                X4_ind = X4[IND]\n",
    "                Frame_Information_Split.append(X4_ind)\n",
    "                Came_from_image.append(ksu)\n",
    "                Parameters_to_split.append([ppf, ppf2, ppf3])\n",
    "                addonarray.append(addon)\n",
    "                temp_numb_of_loc.append(len(IND))\n",
    "                \n",
    "                #This will account for images that allready have less than\n",
    "                #the need number of localizations.\n",
    "                if len(X1) < min_loc:\n",
    "                    flag = 1\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e90bc",
   "metadata": {},
   "source": [
    "Second case : Another approach Matlab like by assigning counter for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before main loop, initialize lists with sufficient length\n",
    "max_possible_splits = 10000000  # Or some conservative upper bound\n",
    "LocalizationsFinal_Split = [None] * max_possible_splits\n",
    "Photons_Split = [None] * max_possible_splits\n",
    "TrueLocalizations_Split = [None] * max_possible_splits\n",
    "cut1array = [None] * max_possible_splits\n",
    "cut2array = [None] * max_possible_splits\n",
    "cut3array = [None] * max_possible_splits\n",
    "Frame_Information_Split = [None] * max_possible_splits\n",
    "Came_from_image = [None] * max_possible_splits\n",
    "Parameters_to_split = [None] * max_possible_splits\n",
    "addonarray = [None] * max_possible_splits\n",
    "\n",
    "# Main processing loop\n",
    "counter = 0\n",
    "for ksu in range(len(Frame_Information)):\n",
    "    print(f\"Processing frame {ksu+1}/{len(Frame_Information)}\")\n",
    "    \n",
    "    # Get the localization data\n",
    "    LF = LocalizationsFinal[ksu]\n",
    "    \n",
    "    # Extract columns - now we know LF has 3 columns\n",
    "    X1, X2, X3 = LF[:,0], LF[:,1], LF[:,2]\n",
    "    \n",
    "    # Handle TrueLocalizations for this frame\n",
    "    has_true_loc = (ksu < len(TrueLocalizations) and \n",
    "                    TrueLocalizations[ksu].size > 0)\n",
    "    \n",
    "    if has_true_loc:\n",
    "        TL = TrueLocalizations[ksu]\n",
    "        X1t, X2t, X3t = TL[:,0], TL[:,1], TL[:,2]\n",
    "    \n",
    "    X4 = Frame_Information[ksu].copy()\n",
    "    addon = 250  # Buffer region\n",
    "    \n",
    "    # Phase space search\n",
    "    scorefinal = np.inf\n",
    "    onwers = 1\n",
    "    while onwers < 300:\n",
    "        print(f'Phase space search progress: {onwers/300:.2f}')\n",
    "        temp_numb_of_loc = []\n",
    "        onwers += 1\n",
    "        pp = random.random()*0.95 + 0.05\n",
    "        pp2 = random.random()*0.95 + 0.05\n",
    "        pp3 = random.random()*0.95 + 0.05 if np.max(X3) != 0 else 1\n",
    "\n",
    "        # Loop over quantile partitions\n",
    "        for i in range(1, math.ceil(1/pp)+1):\n",
    "            if i*pp < 1:\n",
    "                cut1 = np.quantile(X1, [(i-1)*pp, i*pp])\n",
    "            else:\n",
    "                cut1 = np.quantile(X1, [(i-1)*pp, 1])\n",
    "            \n",
    "            for ii in range(1, math.ceil(1/pp2)+1):      \n",
    "                if ii*pp2 < 1:\n",
    "                    cut2 = np.quantile(X2, [(ii-1)*pp2, ii*pp2])\n",
    "                else:\n",
    "                    cut2 = np.quantile(X2, [(ii-1)*pp2, 1])\n",
    "                \n",
    "                for iii in range(1, math.ceil(1/pp3)+1):\n",
    "                    if iii*pp3 < 1:\n",
    "                        cut3 = np.quantile(X3, [(iii-1)*pp3, iii*pp3])\n",
    "                    else:\n",
    "                        cut3 = np.quantile(X3, [(iii-1)*pp3, 1])\n",
    "                    \n",
    "                    # Find indices with conditions and buffer addon\n",
    "                    IND = np.where((X1 >= (cut1[0] - addon)) & (X1 <= (cut1[1] + addon)) & \n",
    "                                   (X2 >= (cut2[0] - addon)) & (X2 <= (cut2[1] + addon)) & \n",
    "                                   (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                    temp_numb_of_loc.append(len(IND))\n",
    "        \n",
    "        # Scoring function\n",
    "        if not temp_numb_of_loc:  # Handle empty list\n",
    "            continue\n",
    "            \n",
    "        # Calculate score\n",
    "        Resid = np.array(temp_numb_of_loc) - min_loc\n",
    "        score = np.sum(Resid**2) / len(temp_numb_of_loc)\n",
    "        \n",
    "        if score < scorefinal:\n",
    "            scorefinal = score\n",
    "            ppf, ppf2, ppf3 = pp, pp2, pp3\n",
    "            onwers = -onwers  # Reset counter\n",
    "            temp_numb_of_locf = temp_numb_of_loc.copy()\n",
    "    \n",
    "    addont = addon\n",
    "    \n",
    "    # Set parameters based on results\n",
    "    pp, pp2, pp3 = ppf, ppf2, ppf3\n",
    "    \n",
    "    if len(X1) < min_loc:\n",
    "        ppf = pp = ppf2 = pp2 = ppf3 = pp3 = 1\n",
    "    \n",
    "    flag = 0\n",
    "\n",
    "\n",
    "    #Now that we know the optimum way to split up our specific image, we\n",
    "    #now split it up. \n",
    "    ##\n",
    "\n",
    "    pp = ppf\n",
    "    pp2 = ppf2\n",
    "    pp3 = ppf3\n",
    "\n",
    "    if len(X1) < min_loc:\n",
    "        ppf = 1\n",
    "        ppf2 = 1\n",
    "        ppf3 = 1\n",
    "        pp = ppf\n",
    "        pp2 = ppf2\n",
    "        pp3 = ppf3\n",
    "\n",
    "    flag = 0\n",
    "\n",
    "    for i in range(1, math.ceil(1/pp) + 1):\n",
    "        if flag == 1:\n",
    "            break\n",
    "        \n",
    "        if i*pp < 1:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, i*pp])\n",
    "        else:\n",
    "            cut1 = np.quantile(X1, [(i-1)*pp, 1])\n",
    "        \n",
    "        for ii in range(1, math.ceil(1/pp2) + 1):\n",
    "            if ii*pp2 < 1:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, ii*pp2])\n",
    "            else:\n",
    "                cut2 = np.quantile(X2, [(ii-1)*pp2, 1])\n",
    "            \n",
    "            for iii in range(1, math.ceil(1/pp3) + 1):\n",
    "                if iii*pp3 < 1:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, iii*pp3])\n",
    "                else:\n",
    "                    cut3 = np.quantile(X3, [(iii-1)*pp3, 1])\n",
    "\n",
    "                addon = addont\n",
    "                \n",
    "                IND = np.array([], dtype=int)\n",
    "                if len(X1) > min_loc:\n",
    "                    # Increase addon until we have enough indices\n",
    "                    while len(IND) < min_loc:\n",
    "                        addon = addon + 10\n",
    "                        IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                        (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                        (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                else:\n",
    "                    IND = np.arange(len(X1))\n",
    "                \n",
    "                while len(IND) > min_loc:\n",
    "                    addon = addon - 10\n",
    "                    IND = np.where((X1 > (cut1[0] - addon)) & (X1 < (cut1[1] + addon)) & \\\n",
    "                                    (X2 > (cut2[0] - addon)) & (X2 < (cut2[1] + addon)) & \\\n",
    "                                    (X3 >= (cut3[0] - addon)) & (X3 <= (cut3[1] + addon)))[0]\n",
    "                    if addon < 150:\n",
    "                        break\n",
    "                    \n",
    "                if (len(TrueLocalizations) != 0) and (isinstance(TrueLocalizations[ksu], np.ndarray)) and (TrueLocalizations[ksu].size != 0):\n",
    "                    INDt = np.where((X1t > (cut1[0] - addon)) & (X1t < (cut1[1] + addon)) & \\\n",
    "                                    (X2t > (cut2[0] - addon)) & (X2t < (cut2[1] + addon)) & \\\n",
    "                                    (X3t >= (cut3[0] - addon)) & (X3t <= (cut3[1] + addon)))[0]\n",
    "                    \n",
    "                # Visualize\n",
    "                try:\n",
    "                    plt.figure(1, figsize=(8, 6))\n",
    "                    plt.clf()  # Clear figure first\n",
    "\n",
    "                    if len(IND) > 0 and len(X4) >= max(IND) + 1:\n",
    "                        c_values = X4[IND]\n",
    "                    else:\n",
    "                        c_values = np.ones(len(IND))\n",
    "                        print(\"Using default colors for visualization\")\n",
    "\n",
    "                    if np.all(X3[IND] == 0):  # 2D plot\n",
    "                        sc = plt.scatter(X1[IND], X2[IND], s=10, c=c_values, cmap='jet')\n",
    "                        plt.axis('equal')\n",
    "                        plt.colorbar(sc)\n",
    "                    else:  # 3D plot\n",
    "                        ax = plt.axes(projection='3d')\n",
    "                        sc = ax.scatter(X1[IND], X2[IND], X3[IND], s=10, c=c_values, cmap='jet')\n",
    "                        plt.colorbar(sc)\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                    plt.title(f\"Split {counter+1}: {len(IND)} points\")\n",
    "                    plt.draw()\n",
    "                    plt.pause(0.5)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to create plot: {e}\")\n",
    "                \n",
    "                # Append split data\n",
    "                LF_split = np.column_stack((X1[IND], X2[IND], X3[IND]))\n",
    "                LocalizationsFinal_Split[counter] = LF_split\n",
    "                Photons_Split[counter] = Photons[ksu][IND]\n",
    "\n",
    "                if has_true_loc:\n",
    "                    TL_split = np.column_stack((X1t[INDt], X2t[INDt], X3t[INDt]))\n",
    "                    TrueLocalizations_Split[counter] = TL_split\n",
    "                else:\n",
    "                    TrueLocalizations_Split[counter] = np.array([])\n",
    "\n",
    "                cut1array[counter] = cut1\n",
    "                cut2array[counter] = cut2\n",
    "                cut3array[counter] = cut3\n",
    "                Frame_Information_Split[counter] = X4[IND]\n",
    "                Came_from_image[counter] = ksu\n",
    "                Parameters_to_split[counter] = [ppf, ppf2, ppf3]\n",
    "                addonarray[counter] = addon\n",
    "\n",
    "                counter += 1 \n",
    "                \n",
    "                #This will account for images that allready have less than\n",
    "                #the need number of localizations.\n",
    "                if len(X1) < min_loc:\n",
    "                    flag = 1\n",
    "                    break\n",
    "\n",
    "    LocalizationsFinal_Split = LocalizationsFinal_Split[:counter]\n",
    "    Photons_Split = Photons_Split[:counter]\n",
    "    TrueLocalizations_Split = TrueLocalizations_Split[:counter]\n",
    "    cut1array = cut1array[:counter]\n",
    "    cut2array = cut2array[:counter]\n",
    "    cut3array = cut3array[:counter]\n",
    "    Frame_Information_Split = Frame_Information_Split[:counter]\n",
    "    Came_from_image = Came_from_image[:counter]\n",
    "    Parameters_to_split = Parameters_to_split[:counter]\n",
    "    addonarray = addonarray[:counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a59db",
   "metadata": {},
   "source": [
    "Finally we update the splitted data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with split data\n",
    "LocalizationsFinal = LocalizationsFinal_Split\n",
    "Frame_Information = Frame_Information_Split\n",
    "TrueLocalizations = TrueLocalizations_Split\n",
    "Photons = Photons_Split\n",
    "\n",
    "print(f\"Created {len(LocalizationsFinal)} split images\")\n",
    "\n",
    "# Prepare data for saving\n",
    "# Convert lists to numpy arrays for proper saving\n",
    "addonarray_np = np.array(addonarray)\n",
    "Came_from_image_np = np.array(Came_from_image)\n",
    "\n",
    "# Prepare dictionary to save\n",
    "save_dict = {\n",
    "    'LocalizationsFinal': np.array(LocalizationsFinal, dtype=object),\n",
    "    'Final_Loc_Blinking_Corrected': np.array(LocalizationsFinal, dtype=object),\n",
    "    'Final_Frame_Blinking_Corrected': np.array(Frame_Information, dtype=object),\n",
    "    'Frame_Information': np.array(Frame_Information, dtype=object),\n",
    "    'addonarray': addonarray_np,\n",
    "    'Parameters_to_split': np.array(Parameters_to_split, dtype=object),\n",
    "    'Came_from_image': Came_from_image_np,\n",
    "    'TrueLocalizations': np.array(TrueLocalizations, dtype=object),\n",
    "    'cut1array': np.array(cut1array, dtype=object),\n",
    "    'cut2array': np.array(cut2array, dtype=object),\n",
    "    'cut3array': np.array(cut3array, dtype=object),\n",
    "    'Resolution': Resolution,\n",
    "    'Photons': np.array(Photons, dtype=object)\n",
    "}\n",
    "\n",
    "# Save the results\n",
    "output_filename = 'Split3_' + Condition\n",
    "try:\n",
    "    sio.savemat(output_filename, save_dict)\n",
    "    print(f'Processing complete. File saved as: {output_filename}')\n",
    "except Exception as e:\n",
    "    print(f\"Error saving output file: {e}\")\n",
    "    # Backup save attempt with simpler structure\n",
    "    try:\n",
    "        simple_dict = {k: v for k, v in save_dict.items() if isinstance(v, (np.ndarray, list))}\n",
    "        sio.savemat(output_filename + \"_backup\", simple_dict)\n",
    "        print(f\"Saved backup file with simpler structure: {output_filename}_backup\")\n",
    "    except:\n",
    "        print(\"Failed to save backup file\")\n",
    "\n",
    "# Clean up\n",
    "plt.close('all')\n",
    "print(\"Script completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
